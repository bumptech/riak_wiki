This is intended to be a brief, objective and technical comparison of Riak and Cassandra.

<div id="toc"></div>

h2. High Level Differences

Both Riak and Cassandra are based on Amazon's description of Dynamo ([[http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html]]), but they take two very different approaches. Riak attempts to be a faithful implementation of Dynamo, including all key components mentioned in the paper, with the addition of some added functionality like links and Map/Reduce operations. Cassandra departs from the Dynamo paper by omitting vector clocks and moving from partition-based consistent hashing to key ranges, while adding functionality like order-preserving partitioners and range queries.

This leads to several major differences detailed below.


h2. Scaling Out

Riak allows you to elastically grow and shrink your cluster while evenly balancing the load on each machine. Adding a new node to a Riak cluster takes one command 'bin/riak join'. When you add a new node, it immediately begins taking an equal share of the existing data from the other machines in the cluster, as well as an equal share of all new requests and data. This works because the available data space for your cluster is divided into partitions (64 by default). When you add a new node, it claims an equal share of the partitions, meaning that every other node has a few less partitions to worry about. When you remove a node, the reverse happens, with the removed node handing partitions back to the remaining nodes in the cluster evenly.

_[[Adding Nodes to Riak|Basic Cluster Setup#Add-a-Second-Node-to-Your-Cluster]]_

In contrast, nodes in a Cassandra cluster claim a range of data. When you add a machine to a Cassandra cluster, by default Cassandra will take on half the key range of whichever node has the largest amount of data stored. Alternatively, you can override this by specifying an InitialToken setting, providing more control over which range is claimed. In this case data is moved from the two nodes on the ring adjacent to the new node. As a result, if all nodes in an N-node cluster were overloaded, you would need to add N/2 new nodes. Cassandra also provides a tool ('nodetool loadbalance') that can be run in a rolling manner on each node to rebalance the cluster.

_[[http://wiki.apache.org/cassandra/Operations]]_

h2. Queries and Distributed Operations

Both Riak and Cassandra allow you to access your data in a simple key/value model.

Riak also allows you to query your data using links and Javascript-based Map/Reduce:

* With links, you create lightweight pointers between your data, for example, from 'projects' to 'milestones' to 'tasks', and then select data along that hierarchy using simple client API commands.


* With Javascript-based Map/Reduce you can define a Map/Reduce operation with multiple map and reduce phases, and then pass the operation to a Riak cluster along with a set of starting keys. Riak works like a mini-Hadoop, running the Map/Reduce operation in real time and returning the results. Any data processing happens in parallel across all machines, and any operations that run on a specific piece of data run on the machine that holds that data.

_[[MapReduce]]_

Cassandra on the other hand, allows you to query your data through data ranges or access your data from Hadoop:

* To use data ranges, the Cassandra database must be configured to use the order-preserving partitioner. (This is a cluster-wide setting.) The order-preserving partitioner requires special care to configure data ranges via the InitialToken setting, otherwise hotspots could result.

* With the upcoming release of Cassandra 0.6, Hadoop will be able to use Cassandra directly from a Map/Reduce job.

_[[http://spyced.blogspot.com/2009/05/consistent-hashing-vs-order-preserving.html]]_
_[[https://svn.apache.org/repos/asf/cassandra/trunk/NEWS.txt]]_




h2. Detecting Conflicting Writes

Riak tags each object with a vector clock, which can be used to detect when two processes try to update the same data at the same time, or to ensure that the correct data is stored after a network split.

_[[Vector Clock|Riak Glossary#Vector Clock]]_

In contrast, Cassandra tags data with a timestamp, and compares timestamps to determine which data is newer. If a client's timestamp is out of sync with the rest of the cluster, or if a client waits too long between reading and writing data, then it is possible to lose the data that was written in between.

_[[http://wiki.apache.org/cassandra/DataModel]]_

h2. Flexible Data Model

Riak buckets are created on the fly when they are first accessed. This allows an application to evolve its data model easily.

_[[Data Storage in Riak|Concepts#Data Storage]]_


In contrast, the Cassandra Keyspaces and Column Families (akin to Databases and Tables) are defined in an XML file. Changing the data-model at this level requires a rolling reboot of the entire cluster.

_[[http://wiki.apache.org/cassandra/DataModel]]_


h2. API

Riak offers two primary interfaces to non-Erlang clients:

_[[HTTP|HTTP API]]_
_[[Protocol Buffers|PBC API]]_

Cassandra uses Thrift, which means that all access must be through a Thrift-based client.

_[[http://wiki.apache.org/cassandra/API]]_

h2. Configurable Storage

Riak allows you to choose different storage backends for different buckets. If your application needs to store both small, frequently-accessed user profiles, and large, less-frequently-accessed MP3 files, you can configure Riak to store these things in a way that optimizes performance and accounts for business tradeoffs. You might store three replicas of the profile in [[Bitcask|https://github.com/basho/bitcask]], the default Riak backed, while storing only one copy of the .mp3 in a filesystem-based backend. This makes Riak appropriate for a wide variety of data and access patterns.

In contrast, as of version 0.5, Cassandra has only one setting for the number of replicas (ReplicationFactor), and persists all data using SSTables. (Cassandra 0.6, currently in beta, will support setting ReplicationFactor at a Keyspace level.)

_[[http://wiki.apache.org/cassandra/StorageConfiguration]]_
_[[http://wiki.apache.org/cassandra/ArchitectureSSTable]]_
